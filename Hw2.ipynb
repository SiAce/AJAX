{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hw2.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SiAce/AJAX/blob/master/Hw2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpzyCphvORjz",
        "colab_type": "text"
      },
      "source": [
        "## <font color='red'>! Warning</font>\n",
        "\n",
        "This notebook might crush the colab runtime after using all available RAM. If this happens, simply click <font color='#dddd00'><ins>Get more RAM</ins></font> in the pop-up message at the bottom left corner:\n",
        "![alt text](https://i.imgur.com/uEhO0k4.png)\n",
        "and then click <font color='#0099ff'>YES</ins></font> in the following message:\n",
        "![alt text](https://i.imgur.com/7yPvpLd.png) to switch to a high-RAM runtime.\n",
        "\n",
        "The estimated execution time of this notebook is 2 hours."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSFFElnctfmn",
        "colab_type": "text"
      },
      "source": [
        "<h1><center><font size=\"5\">AI Project 2 - Continual Learning (CL) for Robotic Perception</font></center></h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1rvQrl3pTwP",
        "colab_type": "text"
      },
      "source": [
        "Zete Dai /zd790  \n",
        "Min Yang /my2138  \n",
        "Xiaorann Sun /xs954  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gF_0omTA-GqW",
        "colab_type": "text"
      },
      "source": [
        "# 1. Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHOKjNXvpWZp",
        "colab_type": "text"
      },
      "source": [
        "## Introduction and backgroud\n",
        "One of the greatest goals of AI is building an artificial continual learning agent which can construct a sophisticated understanding of the external world from its own experience through the adaptive, goal-oriented and incremental development of ever more complex skills and knowledge.  \n",
        "\n",
        "Continual Learning (CL) is built on the idea of learning continuously and adaptively about the external world and enabling the autonomous incremental development of ever more complex skills and knowledge.\n",
        "In the context of Machine Learning it means being able to smoothly update the prediction model to take into account different tasks and data distributions but still being able to re-use and retain useful knowledge and skills during time.\n",
        "\n",
        "Gradient Episodic Memory (GEM) is an effective model for continual learning, where each gradient update for the current task is formulated as a quadratic program problem with inequality constraints that alleviate catastrophic forgetting of previous tasks. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3XaxJjf-MmM",
        "colab_type": "text"
      },
      "source": [
        "## Dataset \n",
        "We choose MNIST due to consideration of the effectiveness.\n",
        "\n",
        "The MNIST database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used for training various image processing systems.\n",
        "\n",
        "The MNIST database contains 60,000 training images and 10,000 testing images. Half of the training set and half of the test set were taken from NIST's training dataset, while the other half of the training set and the other half of the test set were taken from NIST's testing dataset. The original creators of the database keep a list of some of the methods tested on it.\n",
        "\n",
        "We used the dataset provided from [here](https://github.com/facebookresearch/GradientEpisodicMemory).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2J6Qj1q-O-A",
        "colab_type": "text"
      },
      "source": [
        "## Desgin\n",
        "![Flow Chart](https://i.imgur.com/yPhgP9R.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BU9mMMja-TzX",
        "colab_type": "text"
      },
      "source": [
        "# 2. Prepare before implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kAfAQ6zysoc",
        "colab_type": "text"
      },
      "source": [
        "## Install and load packages\n",
        "\n",
        "*   quadprog - Functions to solve quadratic programming problems\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ddhAyCSlW_n",
        "colab_type": "code",
        "outputId": "5d18f1cc-671a-4746-cd48-78906fcfcf96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pip install quadprog"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: quadprog in /usr/local/lib/python3.6/dist-packages (0.1.7)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from quadprog) (0.29.16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5qWK5jSzM07",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   numpy\n",
        "*   quadprog\n",
        "*   torch\n",
        "*   torchvision - The torchvision package consists of popular datasets, model architectures, and common image transformations for computer vision.\n",
        "*   PIL - Python Imaging Library. It is a free library for the Python programming language that adds support for opening, manipulating, and saving many different image file formats.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABzdeNCQFY2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import packages\n",
        "from __future__ import print_function\n",
        "import importlib\n",
        "import datetime\n",
        "import argparse\n",
        "import random\n",
        "import uuid\n",
        "import time\n",
        "import os\n",
        "import numpy as np\n",
        "import subprocess\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import quadprog\n",
        "import math\n",
        "from torch.nn.functional import relu, avg_pool2d\n",
        "from torchvision import transforms\n",
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXRImqiVFaIB",
        "colab_type": "text"
      },
      "source": [
        "Creating namespace."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wj4CoUSbdGOo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class for holding arguments passed into files\n",
        "class Namespace():\n",
        "    def __init__(self, **kwargs):\n",
        "        self.__dict__.update(kwargs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gR5Scr-D1cWJ",
        "colab_type": "text"
      },
      "source": [
        "## Data processing\n",
        "\n",
        "Load data.\n",
        "\n",
        "\n",
        "\n",
        "*   Load data from path `mnist_raw_path`.\n",
        "\n",
        "\n",
        "*   If the path doesn't exist, then load from amazon S3 bucket.\n",
        "\n",
        "\n",
        "*   Divide the dataset into two parts: train and test.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2lsAaiNFaap",
        "colab_type": "code",
        "outputId": "4a5b3f10-e999-445c-d23a-ef2f028a9c6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "#get raw data\n",
        "mnist_raw_path = \"mnist.npz\"\n",
        "if not os.path.exists(mnist_raw_path):\n",
        "  subprocess.call(\"wget https://s3.amazonaws.com/img-datasets/mnist.npz\", shell=True)\n",
        "\n",
        "f = np.load('mnist.npz')\n",
        "x_tr = torch.from_numpy(f['x_train'])\n",
        "y_tr = torch.from_numpy(f['y_train']).long()\n",
        "x_te = torch.from_numpy(f['x_test'])\n",
        "y_te = torch.from_numpy(f['y_test']).long()\n",
        "f.close()\n",
        "\n",
        "torch.save((x_tr, y_tr), 'mnist_train.pt')\n",
        "torch.save((x_te, y_te), 'mnist_test.pt')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 284 ms, sys: 66.5 ms, total: 350 ms\n",
            "Wall time: 348 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QP9qCL3p3nAm",
        "colab_type": "text"
      },
      "source": [
        "Define rotate function.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1M_RkK_6MQRZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#rotate function\n",
        "def rotate_dataset(dataset, rotation):\n",
        "    tensor = transforms.ToTensor()\n",
        "    new_dataset = torch.FloatTensor(dataset.size(0), 784)\n",
        "\n",
        "    for i in range(dataset.size(0)):\n",
        "        img = Image.fromarray(dataset[i].numpy(), mode='L')\n",
        "        new_dataset[i] = tensor(img.rotate(rotation)).view(784)\n",
        "    return new_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsBf3m1s4wW7",
        "colab_type": "text"
      },
      "source": [
        "Randomly rotate the dataset for data augmentation. \n",
        "\n",
        "Data augmentation is a strategy that enables practitioners to significantly increase the diversity of data available for training models, without actually collecting new data. Data augmentation techniques such as cropping, padding, and horizontal flipping are commonly used to train large neural networks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi7TMBsNMx2j",
        "colab_type": "code",
        "outputId": "3e714990-69ec-41ad-f705-c42fa7ea3f1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "#add argument and produce new dataset\n",
        "\n",
        "rotation_args = Namespace(**\n",
        "    {\n",
        "      'i': './',\n",
        "      'o': 'mnist_rotations.pt',\n",
        "      'n_tasks': 20,\n",
        "      'min_rotation': 0.,\n",
        "      'max_rotation': 180.,\n",
        "      'random': 0\n",
        "    }\n",
        ")\n",
        "\n",
        "torch.manual_seed(rotation_args.random)\n",
        "\n",
        "x_tr, y_tr = torch.load(os.path.join(rotation_args.i, 'mnist_train.pt'))\n",
        "x_te, y_te = torch.load(os.path.join(rotation_args.i, 'mnist_test.pt'))\n",
        "\n",
        "new_train_dataset = []\n",
        "new_test_dataset = []\n",
        "for i in range(rotation_args.n_tasks):\n",
        "  min_rotation = i * (rotation_args.max_rotation - rotation_args.min_rotation) / rotation_args.n_tasks + rotation_args.min_rotation\n",
        "  max_rotation = (i + 1) * (rotation_args.max_rotation - rotation_args.min_rotation) / rotation_args.n_tasks + rotation_args.min_rotation\n",
        "  rotation = random.random() * (max_rotation - min_rotation) + min_rotation\n",
        "  new_train_dataset.append([rotation, rotate_dataset(x_tr, rotation), y_tr])\n",
        "  new_test_dataset.append([rotation, rotate_dataset(x_te, rotation), y_te])\n",
        "\n",
        "torch.save([new_train_dataset, new_test_dataset], rotation_args.o)\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3min 33s, sys: 6.75 s, total: 3min 40s\n",
            "Wall time: 4min 48s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktvLEiZ941gq",
        "colab_type": "text"
      },
      "source": [
        "# 3. Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6qE2lEw6f1k",
        "colab_type": "text"
      },
      "source": [
        "## Continuum iterator\n",
        "\n",
        "We can interpret GEM as a model that learns the subset of correlations common to a set of distributions (tasks). Furthermore, GEM can be used to predict target vectors associated to previous or new tasks without making use of task\n",
        "descriptors.  \n",
        "\n",
        "![Algorithm](https://i.imgur.com/cVx1OlW.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qp71DXb_9mIC",
        "colab_type": "code",
        "outputId": "327122fa-f4c1-429b-baa3-8ca65c10e00c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "# /main.py\n",
        "\n",
        "# continuum iterator #########################################################\n",
        "\n",
        "def load_datasets(args):\n",
        "    d_tr, d_te = torch.load(args.data_path + '/' + args.data_file)\n",
        "    n_inputs = d_tr[0][1].size(1)\n",
        "    n_outputs = 0\n",
        "    for i in range(len(d_tr)):\n",
        "        n_outputs = max(n_outputs, d_tr[i][2].max().item())\n",
        "        n_outputs = max(n_outputs, d_te[i][2].max().item())\n",
        "    return d_tr, d_te, n_inputs, n_outputs + 1, len(d_tr)\n",
        "\n",
        "\n",
        "class Continuum:\n",
        "\n",
        "    def __init__(self, data, args):\n",
        "        self.data = data\n",
        "        self.batch_size = args.batch_size\n",
        "        n_tasks = len(data)\n",
        "        task_permutation = range(n_tasks)\n",
        "\n",
        "        if args.shuffle_tasks == 'yes':\n",
        "            task_permutation = torch.randperm(n_tasks).tolist()\n",
        "\n",
        "        sample_permutations = []\n",
        "\n",
        "        for t in range(n_tasks):\n",
        "            N = data[t][1].size(0)\n",
        "            if args.samples_per_task <= 0:\n",
        "                n = N\n",
        "            else:\n",
        "                n = min(args.samples_per_task, N)\n",
        "\n",
        "            p = torch.randperm(N)[0:n]\n",
        "            sample_permutations.append(p)\n",
        "\n",
        "        self.permutation = []\n",
        "\n",
        "        for t in range(n_tasks):\n",
        "            task_t = task_permutation[t]\n",
        "            for _ in range(args.n_epochs):\n",
        "                task_p = [[task_t, i] for i in sample_permutations[task_t]]\n",
        "                random.shuffle(task_p)\n",
        "                self.permutation += task_p\n",
        "\n",
        "        self.length = len(self.permutation)\n",
        "        self.current = 0\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    def next(self):\n",
        "        return self.__next__()\n",
        "\n",
        "    def __next__(self):\n",
        "        if self.current >= self.length:\n",
        "            raise StopIteration\n",
        "        else:\n",
        "            ti = self.permutation[self.current][0]\n",
        "            j = []\n",
        "            i = 0\n",
        "            while (((self.current + i) < self.length) and\n",
        "                   (self.permutation[self.current + i][0] == ti) and\n",
        "                   (i < self.batch_size)):\n",
        "                j.append(self.permutation[self.current + i][1])\n",
        "                i += 1\n",
        "            self.current += i\n",
        "            j = torch.LongTensor(j)\n",
        "            return self.data[ti][1][j], ti, self.data[ti][2][j]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 32 µs, sys: 0 ns, total: 32 µs\n",
            "Wall time: 35.3 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npox1oic9-pq",
        "colab_type": "text"
      },
      "source": [
        "## Data training\n",
        "\n",
        "Define the training functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25Y0NJdb_8di",
        "colab_type": "code",
        "outputId": "f68b38a4-e0e1-4ca9-f942-937a81a15182",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "# train handle ###############################################################\n",
        "\n",
        "\n",
        "def eval_tasks(model, tasks, args):\n",
        "    model.eval()\n",
        "    result = []\n",
        "    for i, task in enumerate(tasks):\n",
        "        t = i\n",
        "        x = task[1]\n",
        "        y = task[2]\n",
        "        rt = 0\n",
        "        \n",
        "        eval_bs = x.size(0)\n",
        "\n",
        "        for b_from in range(0, x.size(0), eval_bs):\n",
        "            b_to = min(b_from + eval_bs, x.size(0) - 1)\n",
        "            if b_from == b_to:\n",
        "                xb = x[b_from].view(1, -1)\n",
        "                yb = torch.LongTensor([y[b_to]]).view(1, -1)\n",
        "            else:\n",
        "                xb = x[b_from:b_to]\n",
        "                yb = y[b_from:b_to]\n",
        "            if args.cuda:\n",
        "                xb = xb.cuda()\n",
        "            _, pb = torch.max(model(xb, t).data.cpu(), 1, keepdim=False)\n",
        "            rt += (pb == yb).float().sum()\n",
        "\n",
        "        result.append(rt / x.size(0))\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def life_experience(model, continuum, x_te, args):\n",
        "    result_a = []\n",
        "    result_t = []\n",
        "\n",
        "    current_task = 0\n",
        "    time_start = time.time()\n",
        "\n",
        "    for (i, (x, t, y)) in enumerate(continuum):\n",
        "        if(((i % args.log_every) == 0) or (t != current_task)):\n",
        "            result_a.append(eval_tasks(model, x_te, args))\n",
        "            result_t.append(current_task)\n",
        "            current_task = t\n",
        "\n",
        "        v_x = x.view(x.size(0), -1)\n",
        "        v_y = y.long()\n",
        "\n",
        "        if args.cuda:\n",
        "            v_x = v_x.cuda()\n",
        "            v_y = v_y.cuda()\n",
        "\n",
        "        model.train()\n",
        "        model.observe(v_x, t, v_y)\n",
        "\n",
        "    result_a.append(eval_tasks(model, x_te, args))\n",
        "    result_t.append(current_task)\n",
        "\n",
        "    time_end = time.time()\n",
        "    time_spent = time_end - time_start\n",
        "\n",
        "    return torch.Tensor(result_t), torch.Tensor(result_a), time_spent\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 5.72 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdT8IRqw__sM",
        "colab_type": "text"
      },
      "source": [
        "Set the arguments `model`,`n_hiddens`, `n_layers`, `n_memories`, `memory_strength`, `finetune`, `n_epochs`, `batch_size`, `lr`, `cuda`, `seed`, `log_every`, `save_path`, `data_path`, `data_file`, `samples_per_task`, `shuffle_tasks`.\n",
        "\n",
        "Set epochs to 100 and using cuda to accelerate the process.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4__YHIu-xcF",
        "colab_type": "code",
        "outputId": "edb0fcc1-c3ed-4495-a052-0cce391e3ed0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "main_args = Namespace(**\n",
        "    {\n",
        "        'model': 'gem',\n",
        "        'n_hiddens': 100,\n",
        "        'n_layers': 2,\n",
        "        'n_memories': 256,\n",
        "        'memory_strength': 0.5,\n",
        "        'finetune': 'no',\n",
        "        'n_epochs': 100,\n",
        "        'batch_size': 10,\n",
        "        'lr': 0.1,\n",
        "        'cuda': 'yes',\n",
        "        'seed': 0,\n",
        "        'log_every': 100,\n",
        "        'save_path': './',\n",
        "        'data_path': './',\n",
        "        'data_file': 'mnist_rotations.pt',\n",
        "        'samples_per_task': 1000,\n",
        "        'shuffle_tasks': 'no'\n",
        "    }\n",
        ")\n",
        "\n",
        "main_args.cuda = True if main_args.cuda == 'yes' else False\n",
        "main_args.finetune = True if main_args.finetune == 'yes' else False\n",
        "\n",
        "# multimodal model has one extra layer\n",
        "if main_args.model == 'multimodal':\n",
        "    main_args.n_layers -= 1\n",
        "\n",
        "# unique identifier\n",
        "uid = uuid.uuid4().hex\n",
        "\n",
        "# initialize seeds\n",
        "torch.backends.cudnn.enabled = False\n",
        "torch.manual_seed(main_args.seed)\n",
        "np.random.seed(main_args.seed)\n",
        "random.seed(main_args.seed)\n",
        "if main_args.cuda:\n",
        "    torch.cuda.manual_seed_all(main_args.seed)\n",
        "\n",
        "# load data\n",
        "x_tr, x_te, n_inputs, n_outputs, n_tasks = load_datasets(main_args)\n",
        "\n",
        "# set up continuum\n",
        "continuum = Continuum(x_tr, main_args)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 9.4 s, sys: 3.05 s, total: 12.4 s\n",
            "Wall time: 12.4 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mFTGtBb-4i8",
        "colab_type": "text"
      },
      "source": [
        "## Architecture\n",
        "\n",
        "On the MNIST task, we use fully-connected neural networks with two hidden layers of 100 ReLU units.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYDgzfP6Axo5",
        "colab_type": "code",
        "outputId": "f9d550af-66dc-47a7-8a1d-87822046a055",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "# load model\n",
        "# /model/gem.py\n",
        "# /model/common.py\n",
        "\n",
        "def Xavier(m):\n",
        "    if m.__class__.__name__ == 'Linear':\n",
        "        fan_in, fan_out = m.weight.data.size(1), m.weight.data.size(0)\n",
        "        std = 1.0 * math.sqrt(2.0 / (fan_in + fan_out))\n",
        "        a = math.sqrt(3.0) * std\n",
        "        m.weight.data.uniform_(-a, a)\n",
        "        m.bias.data.fill_(0.0)\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, sizes):\n",
        "        super(MLP, self).__init__()\n",
        "        layers = []\n",
        "\n",
        "        for i in range(0, len(sizes) - 1):\n",
        "            layers.append(nn.Linear(sizes[i], sizes[i + 1]))\n",
        "            if i < (len(sizes) - 2):\n",
        "                layers.append(nn.ReLU())\n",
        "\n",
        "        self.net = nn.Sequential(*layers)\n",
        "        self.net.apply(Xavier)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                    padding=1, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(in_planes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1,\n",
        "                        stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion * planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes, nf):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = nf\n",
        "\n",
        "        self.conv1 = conv3x3(3, nf * 1)\n",
        "        self.bn1 = nn.BatchNorm2d(nf * 1)\n",
        "        self.layer1 = self._make_layer(block, nf * 1, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, nf * 2, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, nf * 4, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, nf * 8, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(nf * 8 * block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        bsz = x.size(0)\n",
        "        out = relu(self.bn1(self.conv1(x.view(bsz, 3, 32, 32))))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18(nclasses, nf=20):\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2], nclasses, nf)\n",
        "\n",
        "\n",
        "# Auxiliary functions useful for GEM's inner optimization.\n",
        "\n",
        "def compute_offsets(task, nc_per_task, is_cifar):\n",
        "    \"\"\"\n",
        "        Compute offsets for cifar to determine which\n",
        "        outputs to select for a given task.\n",
        "    \"\"\"\n",
        "    if is_cifar:\n",
        "        offset1 = task * nc_per_task\n",
        "        offset2 = (task + 1) * nc_per_task\n",
        "    else:\n",
        "        offset1 = 0\n",
        "        offset2 = nc_per_task\n",
        "    return offset1, offset2\n",
        "\n",
        "\n",
        "def store_grad(pp, grads, grad_dims, tid):\n",
        "    \"\"\"\n",
        "        This stores parameter gradients of past tasks.\n",
        "        pp: parameters\n",
        "        grads: gradients\n",
        "        grad_dims: list with number of parameters per layers\n",
        "        tid: task id\n",
        "    \"\"\"\n",
        "    # store the gradients\n",
        "    grads[:, tid].fill_(0.0)\n",
        "    cnt = 0\n",
        "    for param in pp():\n",
        "        if param.grad is not None:\n",
        "            beg = 0 if cnt == 0 else sum(grad_dims[:cnt])\n",
        "            en = sum(grad_dims[:cnt + 1])\n",
        "            grads[beg: en, tid].copy_(param.grad.data.view(-1))\n",
        "        cnt += 1\n",
        "\n",
        "\n",
        "def overwrite_grad(pp, newgrad, grad_dims):\n",
        "    \"\"\"\n",
        "        This is used to overwrite the gradients with a new gradient\n",
        "        vector, whenever violations occur.\n",
        "        pp: parameters\n",
        "        newgrad: corrected gradient\n",
        "        grad_dims: list storing number of parameters at each layer\n",
        "    \"\"\"\n",
        "    cnt = 0\n",
        "    for param in pp():\n",
        "        if param.grad is not None:\n",
        "            beg = 0 if cnt == 0 else sum(grad_dims[:cnt])\n",
        "            en = sum(grad_dims[:cnt + 1])\n",
        "            this_grad = newgrad[beg: en].contiguous().view(\n",
        "                param.grad.data.size())\n",
        "            param.grad.data.copy_(this_grad)\n",
        "        cnt += 1\n",
        "\n",
        "\n",
        "def project2cone2(gradient, memories, margin=0.5, eps=1e-3):\n",
        "    \"\"\"\n",
        "        Solves the GEM dual QP described in the paper given a proposed\n",
        "        gradient \"gradient\", and a memory of task gradients \"memories\".\n",
        "        Overwrites \"gradient\" with the final projected update.\n",
        "\n",
        "        input:  gradient, p-vector\n",
        "        input:  memories, (t * p)-vector\n",
        "        output: x, p-vector\n",
        "    \"\"\"\n",
        "    memories_np = memories.cpu().t().double().numpy()\n",
        "    gradient_np = gradient.cpu().contiguous().view(-1).double().numpy()\n",
        "    t = memories_np.shape[0]\n",
        "    P = np.dot(memories_np, memories_np.transpose())\n",
        "    P = 0.5 * (P + P.transpose()) + np.eye(t) * eps\n",
        "    q = np.dot(memories_np, gradient_np) * -1\n",
        "    G = np.eye(t)\n",
        "    h = np.zeros(t) + margin\n",
        "    v = quadprog.solve_qp(P, q, G, h)[0]\n",
        "    x = np.dot(v, memories_np) + gradient_np\n",
        "    gradient.copy_(torch.Tensor(x).view(-1, 1))\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self,\n",
        "                n_inputs,\n",
        "                n_outputs,\n",
        "                n_tasks,\n",
        "                args):\n",
        "        super(Net, self).__init__()\n",
        "        nl, nh = args.n_layers, args.n_hiddens\n",
        "        self.margin = args.memory_strength\n",
        "        self.is_cifar = (args.data_file == 'cifar100.pt')\n",
        "        if self.is_cifar:\n",
        "            self.net = ResNet18(n_outputs)\n",
        "        else:\n",
        "            self.net = MLP([n_inputs] + [nh] * nl + [n_outputs])\n",
        "\n",
        "        self.ce = nn.CrossEntropyLoss()\n",
        "        self.n_outputs = n_outputs\n",
        "\n",
        "        self.opt = optim.SGD(self.parameters(), args.lr)\n",
        "\n",
        "        self.n_memories = args.n_memories\n",
        "        self.gpu = args.cuda\n",
        "\n",
        "        # allocate episodic memory\n",
        "        self.memory_data = torch.FloatTensor(\n",
        "            n_tasks, self.n_memories, n_inputs)\n",
        "        self.memory_labs = torch.LongTensor(n_tasks, self.n_memories)\n",
        "        if args.cuda:\n",
        "            self.memory_data = self.memory_data.cuda()\n",
        "            self.memory_labs = self.memory_labs.cuda()\n",
        "\n",
        "        # allocate temporary synaptic memory\n",
        "        self.grad_dims = []\n",
        "        for param in self.parameters():\n",
        "            self.grad_dims.append(param.data.numel())\n",
        "        self.grads = torch.Tensor(sum(self.grad_dims), n_tasks)\n",
        "        if args.cuda:\n",
        "            self.grads = self.grads.cuda()\n",
        "\n",
        "        # allocate counters\n",
        "        self.observed_tasks = []\n",
        "        self.old_task = -1\n",
        "        self.mem_cnt = 0\n",
        "        if self.is_cifar:\n",
        "            self.nc_per_task = int(n_outputs / n_tasks)\n",
        "        else:\n",
        "            self.nc_per_task = n_outputs\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        output = self.net(x)\n",
        "        if self.is_cifar:\n",
        "            # make sure we predict classes within the current task\n",
        "            offset1 = int(t * self.nc_per_task)\n",
        "            offset2 = int((t + 1) * self.nc_per_task)\n",
        "            if offset1 > 0:\n",
        "                output[:, :offset1].data.fill_(-10e10)\n",
        "            if offset2 < self.n_outputs:\n",
        "                output[:, offset2:self.n_outputs].data.fill_(-10e10)\n",
        "        return output\n",
        "\n",
        "    def observe(self, x, t, y):\n",
        "        # update memory\n",
        "        if t != self.old_task:\n",
        "            self.observed_tasks.append(t)\n",
        "            self.old_task = t\n",
        "\n",
        "        # Update ring buffer storing examples from current task\n",
        "        bsz = y.data.size(0)\n",
        "        endcnt = min(self.mem_cnt + bsz, self.n_memories)\n",
        "        effbsz = endcnt - self.mem_cnt\n",
        "        self.memory_data[t, self.mem_cnt: endcnt].copy_(\n",
        "            x.data[: effbsz])\n",
        "        if bsz == 1:\n",
        "            self.memory_labs[t, self.mem_cnt] = y.data[0]\n",
        "        else:\n",
        "            self.memory_labs[t, self.mem_cnt: endcnt].copy_(\n",
        "                y.data[: effbsz])\n",
        "        self.mem_cnt += effbsz\n",
        "        if self.mem_cnt == self.n_memories:\n",
        "            self.mem_cnt = 0\n",
        "\n",
        "        # compute gradient on previous tasks\n",
        "        if len(self.observed_tasks) > 1:\n",
        "            for tt in range(len(self.observed_tasks) - 1):\n",
        "                self.zero_grad()\n",
        "                # fwd/bwd on the examples in the memory\n",
        "                past_task = self.observed_tasks[tt]\n",
        "\n",
        "                offset1, offset2 = compute_offsets(past_task, self.nc_per_task,\n",
        "                                                self.is_cifar)\n",
        "                ptloss = self.ce(\n",
        "                    self.forward(\n",
        "                        self.memory_data[past_task],\n",
        "                        past_task)[:, offset1: offset2],\n",
        "                    self.memory_labs[past_task] - offset1)\n",
        "                ptloss.backward()\n",
        "                store_grad(self.parameters, self.grads, self.grad_dims,\n",
        "                        past_task)\n",
        "\n",
        "        # now compute the grad on the current minibatch\n",
        "        self.zero_grad()\n",
        "\n",
        "        offset1, offset2 = compute_offsets(t, self.nc_per_task, self.is_cifar)\n",
        "        loss = self.ce(self.forward(x, t)[:, offset1: offset2], y - offset1)\n",
        "        loss.backward()\n",
        "\n",
        "        # check if gradient violates constraints\n",
        "        if len(self.observed_tasks) > 1:\n",
        "            # copy gradient\n",
        "            store_grad(self.parameters, self.grads, self.grad_dims, t)\n",
        "            indx = torch.cuda.LongTensor(self.observed_tasks[:-1]) if self.gpu \\\n",
        "                else torch.LongTensor(self.observed_tasks[:-1])\n",
        "            dotp = torch.mm(self.grads[:, t].unsqueeze(0),\n",
        "                            self.grads.index_select(1, indx))\n",
        "            if (dotp < 0).sum() != 0:\n",
        "                project2cone2(self.grads[:, t].unsqueeze(1),\n",
        "                            self.grads.index_select(1, indx), self.margin)\n",
        "                # copy gradients back\n",
        "                overwrite_grad(self.parameters, self.grads[:, t],\n",
        "                            self.grad_dims)\n",
        "        self.opt.step()\n",
        "\n",
        "model = Net(n_inputs, n_outputs, n_tasks, main_args)\n",
        "\n",
        "if main_args.cuda:\n",
        "    model.cuda()\n",
        "\n",
        "# run model on continuum\n",
        "result_t, result_a, spent_time = life_experience(\n",
        "    model, continuum, x_te, main_args)\n",
        "\n",
        "# prepare saving path and file name\n",
        "if not os.path.exists(main_args.save_path):\n",
        "    os.makedirs(main_args.save_path)\n",
        "\n",
        "fname = main_args.model + '_' + main_args.data_file + '_'\n",
        "fname += datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
        "fname += '_' + uid\n",
        "fname = os.path.join(main_args.save_path, fname)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2h 57min 58s, sys: 4h 20min 51s, total: 7h 18min 50s\n",
            "Wall time: 1h 52min 32s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INkenguJBKPV",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation metrics\n",
        "\n",
        "\n",
        "\n",
        "*   confusion matrix\n",
        "\n",
        "A confusion matrix is a table that is often used to describe the performance of a classification model (or “classifier”) on a set of test data for which the true values are known. It allows the visualization of the performance of an algorithm.\n",
        "It allows easy identification of confusion between classes e.g. one class is commonly mislabeled as the other. Most performance measures are computed from the confusion matrix.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "duSWvd3K9i98",
        "outputId": "5dc8f22b-cee0-41e0-e383-5ee86736ec56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "# /metrics/metrics.py\n",
        "def task_changes(result_t):\n",
        "    n_tasks = int(result_t.max() + 1)\n",
        "    changes = []\n",
        "    current = result_t[0]\n",
        "    for i, t in enumerate(result_t):\n",
        "        if t != current:\n",
        "            changes.append(i)\n",
        "            current = t\n",
        "\n",
        "    return n_tasks, changes\n",
        "\n",
        "\n",
        "def confusion_matrix(result_t, result_a, fname=None):\n",
        "    nt, changes = task_changes(result_t)\n",
        "\n",
        "    baseline = result_a[0]\n",
        "    changes = torch.LongTensor(changes + [result_a.size(0)]) - 1\n",
        "    result = result_a[changes]\n",
        "\n",
        "    # acc[t] equals result[t,t]\n",
        "    acc = result.diag()\n",
        "    fin = result[nt - 1]\n",
        "    # bwt[t] equals result[T,t] - acc[t]\n",
        "    bwt = result[nt - 1] - acc\n",
        "\n",
        "    # fwt[t] equals result[t-1,t] - baseline[t]\n",
        "    fwt = torch.zeros(nt)\n",
        "    for t in range(1, nt):\n",
        "        fwt[t] = result[t - 1, t] - baseline[t]\n",
        "\n",
        "    if fname is not None:\n",
        "        f = open(fname, 'w')\n",
        "\n",
        "        print(' '.join(['%.4f' % r for r in baseline]), file=f)\n",
        "        print('|', file=f)\n",
        "        for row in range(result.size(0)):\n",
        "            print(' '.join(['%.4f' % r for r in result[row]]), file=f)\n",
        "        print('', file=f)\n",
        "        # print('Diagonal Accuracy: %.4f' % acc.mean(), file=f)\n",
        "        print('Final Accuracy: %.4f' % fin.mean(), file=f)\n",
        "        print('Backward: %.4f' % bwt.mean(), file=f)\n",
        "        print('Forward:  %.4f' % fwt.mean(), file=f)\n",
        "        f.close()\n",
        "\n",
        "    stats = []\n",
        "    # stats.append(acc.mean())\n",
        "    stats.append(fin.mean())\n",
        "    stats.append(bwt.mean())\n",
        "    stats.append(fwt.mean())\n",
        "\n",
        "    return stats\n",
        "    \n",
        "# save confusion matrix and print one line of stats\n",
        "stats = confusion_matrix(result_t, result_a, fname + '.txt')\n",
        "one_liner = str(vars(main_args)) + ' # '\n",
        "one_liner += ' '.join([\"%.3f\" % stat for stat in stats])\n",
        "print(fname + ': ' + one_liner + ' # ' + str(spent_time))\n",
        "\n",
        "# save all results in binary file\n",
        "torch.save((result_t, result_a, model.state_dict(),\n",
        "            stats, one_liner, main_args), fname + '.pt')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./gem_mnist_rotations.pt_2020_04_05_23_23_15_acb9dfeee10847b28ddf4c8105e45896: {'model': 'gem', 'n_hiddens': 100, 'n_layers': 2, 'n_memories': 256, 'memory_strength': 0.5, 'finetune': False, 'n_epochs': 100, 'batch_size': 10, 'lr': 0.1, 'cuda': True, 'seed': 0, 'log_every': 100, 'save_path': './', 'data_path': './', 'data_file': 'mnist_rotations.pt', 'samples_per_task': 1000, 'shuffle_tasks': 'no'} # 0.884 -0.024 0.729 # 6744.08793759346\n",
            "CPU times: user 24.2 ms, sys: 0 ns, total: 24.2 ms\n",
            "Wall time: 36.3 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Is5aR9Fl7pWD",
        "colab_type": "text"
      },
      "source": [
        "# 4. Visualization\n",
        "\n",
        "Visualise the result using Matplotlib.\n",
        "\n",
        "\n",
        "\n",
        "*   Matplotlib is a plotting library for the Python programming language and its numerical mathematics extension NumPy. It provides an object-oriented API for embedding plots into applications using general-purpose GUI toolkits like Tkinter, wxPython, Qt, or GTK+.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8K-JllUYO4eP",
        "colab_type": "code",
        "outputId": "ba4c836f-5694-45d6-89d9-e3ce1b570a91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "import matplotlib as mpl\n",
        "from matplotlib import pyplot as plt\n",
        "from glob import glob\n",
        "\n",
        "#Visualization\n",
        "mpl.use('Agg')\n",
        "\n",
        "models = ['gem']\n",
        "datasets = ['mnist_rotations']\n",
        "\n",
        "names_datasets = {'mnist_rotations': 'MNIST rotations'}\n",
        "\n",
        "names_models = {'gem': 'GEM'}\n",
        "\n",
        "colors = {'gem': 'C0'}\n",
        "\n",
        "barplot = {}\n",
        "\n",
        "for dataset in datasets:\n",
        "    barplot[dataset] = {}\n",
        "    for model in models:\n",
        "        barplot[dataset][model] = {}\n",
        "        matches = glob(model + '*' + dataset + '*.pt')\n",
        "        if len(matches):\n",
        "            data = torch.load(matches[0], map_location=lambda storage, loc: storage)\n",
        "            acc, bwt, fwt = data[3][:]\n",
        "            barplot[dataset][model]['acc'] = acc\n",
        "            barplot[dataset][model]['bwt'] = bwt\n",
        "            barplot[dataset][model]['fwt'] = fwt\n",
        "\n",
        "for dataset in datasets:\n",
        "    x_lab = []\n",
        "    y_acc = []\n",
        "    y_bwt = []\n",
        "    y_fwt = []\n",
        "\n",
        "    for i, model in enumerate(models):\n",
        "        if barplot[dataset][model] != {}:\n",
        "            x_lab.append(model)\n",
        "            y_acc.append(barplot[dataset][model]['acc'])\n",
        "            y_bwt.append(barplot[dataset][model]['bwt'])\n",
        "            y_fwt.append(barplot[dataset][model]['fwt'])\n",
        "\n",
        "    x_ind = np.arange(len(y_acc))\n",
        "\n",
        "    plt.figure(figsize=(7, 3))\n",
        "    all_colors = []\n",
        "    for xi, yi, li in zip(x_ind, y_acc, x_lab):\n",
        "        plt.bar(xi, yi, label=names_models[li], color=colors[li])\n",
        "        all_colors.append(colors[li])\n",
        "    plt.bar(x_ind + (len(y_acc) + 1) * 1, y_bwt, color=all_colors)\n",
        "    plt.bar(x_ind + (len(y_acc) + 1) * 2, y_fwt, color=all_colors)\n",
        "    plt.xticks([0, 2, 4], ['ACC', 'BWT', 'FWT'], fontsize=16)\n",
        "    plt.yticks(fontsize=16)\n",
        "    plt.xlim(-1, len(y_acc) * 3 + 2)\n",
        "    plt.ylabel('classification accuracy', fontsize=16)\n",
        "    plt.title(names_datasets[dataset], fontsize=16)\n",
        "    plt.legend(fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('barplot_%s.jpg' % dataset, bbox_inches='tight')\n",
        "\n",
        "evoplot = {}\n",
        "\n",
        "for dataset in datasets:\n",
        "    evoplot[dataset] = {}\n",
        "    for model in models:\n",
        "        matches = glob(model + '*' + dataset + '*.pt')\n",
        "        if len(matches):\n",
        "            data = torch.load(matches[0], map_location=lambda storage, loc: storage)\n",
        "            evoplot[dataset][model] = data[1][:, 0].numpy()\n",
        "\n",
        "for dataset in datasets:\n",
        "\n",
        "    plt.figure(figsize=(7, 3))\n",
        "    for model in models:\n",
        "        if model in evoplot[dataset]:\n",
        "            x = np.arange(len(evoplot[dataset][model]))\n",
        "            x = (x - x.min()) / (x.max() - x.min()) * 20\n",
        "            plt.plot(x, evoplot[dataset][model], color=colors[model], lw=3)\n",
        "            plt.xticks(range(0, 21, 2))\n",
        "\n",
        "    plt.xticks(fontsize=16)\n",
        "    plt.yticks(fontsize=16)\n",
        "    plt.xlabel('task number', fontsize=16)\n",
        "    plt.title(names_datasets[dataset], fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('evoplot_%s.jpg' % dataset, bbox_inches='tight')\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 517 ms, sys: 406 ms, total: 923 ms\n",
            "Wall time: 435 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-nQT1FYB1DJ",
        "colab_type": "text"
      },
      "source": [
        "# 5. Result and Output\n",
        "\n",
        "## Running log and statistics\n",
        "\n",
        "0.1111 0.1215 0.1218 0.1232 0.0901 0.0901 0.0787 0.0837 0.0654 0.0720 0.0687 0.0643 0.0478 0.0423 0.0507 0.0556 0.0648 0.0718 0.0786 0.0767\n",
        "|\n",
        "0.9030 0.8121 0.6356 0.5782 0.3703 0.2999 0.2030 0.1716 0.1383 0.1245 0.1182 0.1094 0.1100 0.1287 0.1547 0.1750 0.1870 0.1924 0.1998 0.2128\n",
        "0.9070 0.9199 0.8400 0.8047 0.5817 0.4926 0.3151 0.2370 0.1633 0.1516 0.1397 0.1177 0.1042 0.1159 0.1413 0.1766 0.1985 0.2191 0.2194 0.2340\n",
        "0.8824 0.9323 0.9304 0.9163 0.8125 0.7323 0.5218 0.3946 0.2274 0.1977 0.1814 0.1479 0.1294 0.1274 0.1402 0.1633 0.1884 0.2218 0.2294 0.2423\n",
        "0.8775 0.9368 0.9415 0.9356 0.8636 0.7932 0.5900 0.4568 0.2553 0.2081 0.1859 0.1406 0.1092 0.1068 0.1197 0.1394 0.1657 0.1957 0.2038 0.2142\n",
        "0.8547 0.9217 0.9404 0.9391 0.9224 0.8886 0.7567 0.6308 0.3908 0.3036 0.2712 0.1860 0.1344 0.1230 0.1318 0.1430 0.1669 0.2026 0.2175 0.2358\n",
        "0.8525 0.9164 0.9355 0.9383 0.9384 0.9260 0.8556 0.7694 0.5164 0.4230 0.3698 0.2336 0.1606 0.1419 0.1425 0.1594 0.1755 0.2087 0.2156 0.2294\n",
        "0.8479 0.9049 0.9247 0.9277 0.9422 0.9428 0.9187 0.8849 0.6939 0.5997 0.5365 0.3428 0.2177 0.1679 0.1558 0.1639 0.1777 0.2057 0.2080 0.2178\n",
        "0.8332 0.8965 0.9135 0.9216 0.9349 0.9378 0.9303 0.9132 0.8140 0.7516 0.6905 0.4884 0.3009 0.1996 0.1765 0.1668 0.1734 0.1987 0.2078 0.2122\n",
        "0.8211 0.8874 0.9055 0.9106 0.9228 0.9258 0.9289 0.9245 0.9079 0.8689 0.8417 0.6878 0.4761 0.2933 0.2180 0.1814 0.1819 0.1983 0.1999 0.2025\n",
        "0.8185 0.8871 0.9024 0.9077 0.9202 0.9220 0.9270 0.9272 0.9214 0.9066 0.8857 0.7883 0.5688 0.3789 0.2742 0.2083 0.1985 0.2065 0.2082 0.2080\n",
        "0.8117 0.8882 0.9034 0.9046 0.9141 0.9169 0.9247 0.9260 0.9347 0.9282 0.9188 0.8512 0.6712 0.4666 0.3472 0.2466 0.2151 0.1994 0.1984 0.2086\n",
        "0.8111 0.8850 0.8995 0.9024 0.9036 0.9056 0.9144 0.9163 0.9291 0.9312 0.9328 0.9128 0.7958 0.6207 0.4824 0.3376 0.2796 0.2337 0.2179 0.2087\n",
        "0.7986 0.8734 0.8924 0.8983 0.9040 0.9047 0.9098 0.9090 0.9156 0.9217 0.9286 0.9225 0.8995 0.8128 0.7180 0.5489 0.4560 0.3543 0.2907 0.2513\n",
        "0.7810 0.8690 0.8900 0.8942 0.8997 0.9002 0.9015 0.8971 0.9032 0.9062 0.9149 0.9172 0.9174 0.8922 0.8383 0.7181 0.6026 0.4502 0.3477 0.2721\n",
        "0.7725 0.8674 0.8921 0.8965 0.9025 0.9001 0.8978 0.8919 0.8934 0.8990 0.9066 0.9162 0.9251 0.9195 0.8984 0.8101 0.7040 0.5298 0.3833 0.2645\n",
        "0.7723 0.8668 0.8913 0.8948 0.8975 0.8996 0.8947 0.8868 0.8887 0.8956 0.9007 0.9053 0.9176 0.9220 0.9169 0.8949 0.8513 0.7330 0.5896 0.4232\n",
        "0.7819 0.8705 0.8912 0.8940 0.8963 0.8960 0.8894 0.8835 0.8879 0.8912 0.8958 0.8992 0.9123 0.9238 0.9221 0.9202 0.9008 0.8183 0.6882 0.5044\n",
        "0.7694 0.8635 0.8884 0.8916 0.8949 0.8939 0.8895 0.8812 0.8833 0.8837 0.8896 0.8933 0.9010 0.9111 0.9160 0.9280 0.9194 0.9002 0.8256 0.6756\n",
        "0.7666 0.8600 0.8842 0.8882 0.8954 0.8908 0.8855 0.8754 0.8757 0.8803 0.8817 0.8842 0.8922 0.9041 0.9065 0.9193 0.9220 0.9209 0.8977 0.8195\n",
        "0.7617 0.8611 0.8844 0.8917 0.8986 0.8948 0.8893 0.8809 0.8749 0.8781 0.8804 0.8830 0.8899 0.8987 0.8967 0.9112 0.9167 0.9229 0.9189 0.8912\n",
        "\n",
        "Final Accuracy: 0.8863\n",
        "Backward: -0.0233\n",
        "Forward:  0.7292\n",
        "\n",
        "\n",
        "CPU times: user 1h 30min 15s, sys: 1h 3min 5s, total: 2h 33min 20s\n",
        "Wall time: 1h 21min 50s\n",
        "\n",
        "## Output\n",
        "\n",
        "The results are two output jpg files\n",
        "\n",
        "1. evoplot_mnist_rotations.jpg  \n",
        "\n",
        "![evoplot_mnist_rotations.jpg](https://i.imgur.com/85kRLdi.jpg)\n",
        "\n",
        "2. barplot_mnist_rotations.jpg\n",
        "\n",
        "![barplot_mnist_rotations.jpg](https://i.imgur.com/VVeEabZ.jpg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWFqU80LB7bn",
        "colab_type": "text"
      },
      "source": [
        "# 6. References\n",
        "\n",
        "[1] https://en.wikipedia.org/wiki/MNIST_database  \n",
        "[2] http://yann.lecun.com/exdb/mnist/  \n",
        "[3] https://openreview.net/forum?id=H1g79ySYvB  \n",
        "[4] https://medium.com/continual-ai/why-continuous-learning-is-the-key-towards-  \n",
        "[5] https://www.geeksforgeeks.org/confusion-matrix-machine-learning/  \n",
        "[6] https://github.com/facebookresearch/GradientEpisodicMemory  \n",
        "[7] [Gradient Episodic Memory for Continual Learning](https://arxiv.org/pdf/1706.08840.pdf)  \n",
        "[8] [Continual Lifelong Learning with Neural Networks:\n",
        "A Review](https://arxiv.org/pdf/1802.07569.pdf)  "
      ]
    }
  ]
}